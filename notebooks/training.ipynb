{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 🏋️ Training sentence_transformers using ČTK data\n",
    "Shared notebook version 1.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📑 Import Clauses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb687e0f-0255-4f12-b0ee-9e6f76161079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, logging, math, os, pickle, gc\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers.evaluation import (\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.readers import InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datautils\n",
    "from datautils import detokenize2\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ⚓ Load a dataset (see [Dataset NB](datasets.ipynb))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0792d1a1-fed9-41c9-ac73-dc2fa89c1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_examples, tst_examples, val_examples = datautils.load_examples_from_pickle(\"../data/demo_splits/pickle\")\n",
    "[datautils.counter(split) for split in (trn_examples, tst_examples, val_examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trn_examples[0].texts,trn_examples[0].label,val_examples[0].texts,val_examples[0].label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📂 Prepare an output directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outdir = \"../models\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📅 Schedule a bunch of training jobs!\n",
    "Set parameters for each in respective if's - omit them if not needed, alter the iterated range if some are to be skipped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    if i == 0:\n",
    "        bert_name = (bert_name_short) = \"deepset/xlm-roberta-large-squad2\"  # \"DeepPavlov/bert-base-multilingual-cased-sentence\" #\"bert-base-multilingual-cased\"  # \"deepset/xlm-roberta-large-squad2\"\n",
    "        max_length = None\n",
    "        batch_size = 12\n",
    "        num_epochs = 30\n",
    "        model_name = f\"{bert_name_short}_bs{batch_size}\"\n",
    "    elif i == 1:\n",
    "        bert_name = (bert_name_short) = \"DeepPavlov/bert-base-multilingual-cased-sentence\"  # \"bert-base-multilingual-cased\"  # \"deepset/xlm-roberta-large-squad2\"\n",
    "        max_length = 512\n",
    "        batch_size = 7\n",
    "        num_epochs = 30\n",
    "        model_name = f\"{bert_name_short}_bs{batch_size}\"\n",
    "    if i == 2:\n",
    "        bert_name = (\n",
    "            bert_name_short\n",
    "        ) = \"deepset/xlm-roberta-large-squad2\"  # \"DeepPavlov/bert-base-multilingual-cased-sentence\" #\"bert-base-multilingual-cased\"  # \"deepset/xlm-roberta-large-squad2\"\n",
    "        max_length = None\n",
    "        batch_size = 8\n",
    "        num_epochs = 30\n",
    "        model_name = f\"{bert_name_short}_bs{batch_size}\"\n",
    "\n",
    "    output_path = pjoin(outdir, model_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    logger.info(f\"output path: {output_path}\")\n",
    "    pickle.dump(trn_examples, open(pjoin(output_path, \"trn_examples.p\"), \"wb\"))\n",
    "    pickle.dump(tst_examples, open(pjoin(output_path, \"tst_examples.p\"), \"wb\"))\n",
    "    pickle.dump(val_examples, open(pjoin(output_path, \"val_examples.p\"), \"wb\"))\n",
    "\n",
    "    cfg = OrderedDict(\n",
    "        [\n",
    "            (\"bert_name\", bert_name),\n",
    "            (\"bert_name_short\", bert_name_short),\n",
    "            (\"batch_size\", batch_size),\n",
    "            (\"max_length\", max_length),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(pjoin(output_path, \"rteconfig.json\"), \"w\") as outfile:\n",
    "        outfile.write(json.dumps(cfg, indent=3))\n",
    "\n",
    "    trn_dataloader = DataLoader(trn_examples, shuffle=True, batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(val_examples, shuffle=False, batch_size=batch_size)\n",
    "    tst_dataloader = DataLoader(tst_examples, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    trn_evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(trn_examples, name=\"train\")\n",
    "    val_evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(val_examples, name=\"validation\")\n",
    "    tst_evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(tst_examples, name=\"test\")\n",
    "\n",
    "    # 10% of train data for warm-up\n",
    "    warmup_steps = math.ceil(len(trn_dataloader) * num_epochs * 0.1)\n",
    "    logger.info(f\"warmup_steps: {warmup_steps}\")\n",
    "\n",
    "    model = CrossEncoder(bert_name, num_labels=3, max_length=max_length)\n",
    "\n",
    "    def cb(score, epoch, steps):\n",
    "        logger.info(f\"E{epoch}: score: {score}\")\n",
    "        if score > model.best_score: logger.info(f\"new best model for score: {score}\")\n",
    "\n",
    "    model.fit(\n",
    "        train_dataloader=trn_dataloader,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        evaluator=SequentialEvaluator([trn_evaluator, val_evaluator]),\n",
    "        output_path=output_path,\n",
    "        callback=cb,\n",
    "        save_best_model=True,\n",
    "    )\n",
    "\n",
    "    model = CrossEncoder(output_path, max_length=max_length)\n",
    "    if 'evals' not in globals(): evals = {}\n",
    "    evals[output_path] = tst_evaluator(model, output_path=output_path)\n",
    "    tst_evaluator(model, output_path=output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 🤯 Out of memory? Free some!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "caae8213-4ea5-41bb-b1ec-91336bce5862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📜 How did Your models do?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa60eae1-b438-4f6a-9956-82da1eecaaf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}