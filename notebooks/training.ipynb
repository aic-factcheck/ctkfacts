{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-agreement",
   "metadata": {},
   "source": [
    "# ðŸ‹ï¸ Training sentence_transformers using ÄŒTK data\n",
    "Shared notebook version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fb3de4-4a23-4132-8347-c31554fe9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-regular",
   "metadata": {},
   "source": [
    "## ðŸ“‘ Import Clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb687e0f-0255-4f12-b0ee-9e6f76161079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, logging, math, os, pickle, gc\n",
    "from collections import Counter, OrderedDict\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers.evaluation import (\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.readers import InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datautils\n",
    "from datautils import LABEL_NUM, LABEL_STR\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-destiny",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## âš“ Load a dataset (see [Dataset NB](datasets.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0792d1a1-fed9-41c9-ac73-dc2fa89c1b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('NOT ENOUGH INFO', 1021, 0.2815774958632101),\n",
       "  ('REFUTES', 851, 0.23469387755102042),\n",
       "  ('SUPPORTS', 1754, 0.48372862658576943)],\n",
       " [('NOT ENOUGH INFO', 177, 0.36721991701244816),\n",
       "  ('REFUTES', 114, 0.23651452282157676),\n",
       "  ('SUPPORTS', 191, 0.3962655601659751)],\n",
       " [('NOT ENOUGH INFO', 183, 0.3279569892473118),\n",
       "  ('REFUTES', 115, 0.2060931899641577),\n",
       "  ('SUPPORTS', 260, 0.4659498207885305)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_examples, tst_examples, val_examples = datautils.load_examples_from_pickle(\"../data/demo_splits/pickle\")\n",
    "[datautils.counter(split) for split in (trn_examples, tst_examples, val_examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funded-contribution",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PRAHA 18. Äervna (ÄŒTK) - RekordnÃ­ teploty 19. Äervna (od roku 1775 mÄ›Å™enÃ© v praÅ¾skÃ©m Klementinu) byly nÃ¡sledujÃ­cÃ­: nejvyÅ¡Å¡Ã­ teplota 31,2 z roku 1917 a 1934, nejniÅ¾Å¡Ã­ teplota 7,3 z roku 1985\\\\. DlouhodobÃ½ prÅ¯mÄ›rnÃ½ normÃ¡l: 17,9 stupnÄ› Celsia.',\n",
       "  'RekordnÃ­ teploty se od roku 1775 mÄ›Å™Ã­ v Praze.'],\n",
       " 0,\n",
       " ['ÄŒeskÃ© ministerstvo Å¾ivotnÃ­ho prostÅ™edÃ­ v Å™Ã­jnu oznÃ¡milo, Å¾e povolilo prÅ¯zkum pro trvalÃ© ÃºloÅ¾iÅ¡tÄ› radioaktivnÃ­ho odpadu. GeologickÃ© prÅ¯zkumnÃ© prÃ¡ce a posuzovÃ¡nÃ­ vhodnosti hlubinnÃ½ch ÃºloÅ¾iÅ¡Å¥ se tÃ½kÃ¡ celkem sedmi lokalit, o nÄ›Å¾ Å¾Ã¡dala SprÃ¡va ÃºloÅ¾iÅ¡Å¥ radioaktivnÃ­ch odpadÅ¯ (SÃšRAO). â€žV zÃ¡sadÄ› jsme nemÄ›li Å¾Ã¡dnÃ© zÃ¡konnÃ© dÅ¯vody pro neudÄ›lenÃ­ povolenÃ­,â€œ uvedl Brabec s tÃ­m, Å¾e jde o pÅ™edbÄ›Å¾nÃ½ prÅ¯zkum, mapovÃ¡nÃ­ lokalit. â€žVyjÃ¡dÅ™enÃ­ z rakouskÃ© strany beru v Ãºvahu, vÅ¡ichni vÃ­me, Å¾e RakuÅ¡anÃ© se stavÃ­ proti jadernÃ½m elektrÃ¡rnÃ¡m,â€œ uvedl Brabec s tÃ­m, Å¾e pro diskusi bude Äas a se svÃ½m rakouskÃ½m protÄ›jÅ¡kem ji uÅ¾ zahÃ¡jil.',\n",
       "  'ÄŒeskÃ© ministerstvo Å¾ivotnÃ­ho prostÅ™edÃ­ zakÃ¡zalo prÅ¯zkum pro trvalÃ© ÃºloÅ¾iÅ¡tÄ› radioaktivnÃ­ho odpadu.'],\n",
       " 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_examples[0].texts,trn_examples[0].label,val_examples[0].texts,val_examples[0].label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-contrast",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ðŸ“‚ Prepare an output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "familiar-puppy",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outdir = \"../models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-insulin",
   "metadata": {},
   "source": [
    "## ðŸ“… Schedule a bunch of training jobs!\n",
    "Set parameters for each in respective if's - omit them if not needed, alter the iterated range if some are to be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "starting-boost",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaForSequenceClassification: ['qa_outputs.weight', 'qa_outputs.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at deepset/xlm-roberta-large-squad2 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6147de71ad7c4903b44a8100d3f49439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=30.0, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa7a9c798eb485b99d8e679c04f00e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733332b423f04853a557a0c6b7f4f497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f61d16ac65425395a961b96449e2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d115a966664c6cbf6e9fdd7bb4e626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b9851ee2b346f99043779640b237ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8373f95690bd403194e59903a7fddbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8002676353446609524be4d1e8e524f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470a2671d53141de894d039865e305ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efd6a6204914a9eb95e9de5d71e253d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835c9fe1168a4d9bba7985bb2ab8c8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84037af44724477a86a2e9706ca6c88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635bd76edc374efd847100c8b2b37731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960c75d4a18747fc95b0e2767adbcc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9e4343261a4a36ac8f90d14c8ee0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df749939787146e8b13e68b56a45c35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d38e73b9a54297aa937b5d3e98dbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=518.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 3):\n",
    "    if i == 0:\n",
    "        bert_name = (bert_name_short) = \"deepset/xlm-roberta-large-squad2\"  # \"DeepPavlov/bert-base-multilingual-cased-sentence\" #\"bert-base-multilingual-cased\"  # \"deepset/xlm-roberta-large-squad2\"\n",
    "        max_length = None\n",
    "        batch_size = 12\n",
    "        num_epochs = 30\n",
    "        model_name = f\"{bert_name_short}_bs{batch_size}\"\n",
    "    elif i == 1:\n",
    "        bert_name = (bert_name_short) = \"DeepPavlov/bert-base-multilingual-cased-sentence\"  # \"bert-base-multilingual-cased\"  # \"deepset/xlm-roberta-large-squad2\"\n",
    "        max_length = 512\n",
    "        batch_size = 7\n",
    "        num_epochs = 30\n",
    "        model_name = f\"{bert_name_short}_bs{batch_size}\"\n",
    "    if i == 2:\n",
    "        bert_name = (bert_name_short) = \"deepset/xlm-roberta-large-squad2\"  # \"DeepPavlov/bert-base-multilingual-cased-sentence\" #\"bert-base-multilingual-cased\"  # \"deepset/xlm-roberta-large-squad2\"\n",
    "        max_length = None\n",
    "        batch_size =7\n",
    "        num_epochs = 30\n",
    "        model_name = f\"{bert_name_short}_bs{batch_size}\"\n",
    "\n",
    "    output_path = pjoin(outdir, model_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    logger.info(f\"output path: {output_path}\")\n",
    "    pickle.dump(trn_examples, open(pjoin(output_path, \"trn_examples.p\"), \"wb\"))\n",
    "    pickle.dump(tst_examples, open(pjoin(output_path, \"tst_examples.p\"), \"wb\"))\n",
    "    pickle.dump(val_examples, open(pjoin(output_path, \"val_examples.p\"), \"wb\"))\n",
    "\n",
    "    cfg = OrderedDict(\n",
    "        [\n",
    "            (\"bert_name\", bert_name),\n",
    "            (\"bert_name_short\", bert_name_short),\n",
    "            (\"batch_size\", batch_size),\n",
    "            (\"max_length\", max_length),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(pjoin(output_path, \"rteconfig.json\"), \"w\") as outfile:\n",
    "        outfile.write(json.dumps(cfg, indent=3))\n",
    "\n",
    "    trn_dataloader = DataLoader(trn_examples, shuffle=True, batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(val_examples, shuffle=False, batch_size=batch_size)\n",
    "    tst_dataloader = DataLoader(tst_examples, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    trn_evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(trn_examples, name=\"train\")\n",
    "    val_evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(val_examples, name=\"validation\")\n",
    "    tst_evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(tst_examples, name=\"test\")\n",
    "\n",
    "    # 10% of train data for warm-up\n",
    "    warmup_steps = math.ceil(len(trn_dataloader) * num_epochs * 0.1)\n",
    "    logger.info(f\"warmup_steps: {warmup_steps}\")\n",
    "\n",
    "    model = CrossEncoder(bert_name, num_labels=3, max_length=max_length)\n",
    "\n",
    "    def cb(score, epoch, steps):\n",
    "        logger.info(f\"E{epoch}: score: {score}\")\n",
    "        if score > model.best_score: logger.info(f\"new best model for score: {score}\")\n",
    "\n",
    "    model.fit(\n",
    "        train_dataloader=trn_dataloader,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        evaluator=SequentialEvaluator([trn_evaluator, val_evaluator]),\n",
    "        output_path=output_path,\n",
    "        callback=cb,\n",
    "        save_best_model=True,\n",
    "    )\n",
    "\n",
    "    model = CrossEncoder(output_path, max_length=max_length)\n",
    "    if 'evals' not in globals(): evals = {}\n",
    "    evals[output_path] = tst_evaluator(model, output_path=output_path)\n",
    "    tst_evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-jefferson",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ðŸ¤¯ Out of memory? Free some!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caae8213-4ea5-41bb-b1ec-91336bce5862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6805"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-wellington",
   "metadata": {},
   "source": [
    "## ðŸ“œ How did Your models do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa60eae1-b438-4f6a-9956-82da1eecaaf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
